# XGBoost Demo ğŸš€  

A machine learning project demonstrating **XGBoost** for classification tasks, with support for structured and unstructured data (via LangChain). Now includes visualization features to analyze model performance.  

## ğŸ“Œ Features  
- **XGBoost Model** for classification  
- **Overfitting Prevention** using early stopping & regularization  
- **Feature Engineering** from structured & unstructured data  
- **LangChain Integration** for text feature extraction  
- **Data Visualization** with saved plots  

---

## ğŸ“‚ Project Structure  
```
xgboost-demo/
â”‚â”€â”€ xgboost_demo.py        # Main script for training XGBoost on structured data
â”‚â”€â”€ xgboost_langchain.py   # XGBoost with LangChain-enhanced text processing
â”‚â”€â”€ xgboost_plots.py       # XGBoost with data visualization and saved plots
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ .gitignore             # Files to ignore in Git
â”‚â”€â”€ README.md              # Project documentation
â”‚â”€â”€ data/                  # (Optional) Folder for datasets
â”‚â”€â”€ models/                # (Optional) Folder to save trained models
â”‚â”€â”€ plots/                 # Folder where plots are saved
```

---

## ğŸ“¦ Installation  
Clone the repository and install dependencies:  

```bash
git clone https://github.com/your-repo/xgboost-demo.git
cd xgboost-demo
pip install -r requirements.txt
```

---

## ğŸš€ Usage  

### **Run the Standard XGBoost Model (Structured Data Only):**  
```bash
python xgboost_demo.py
```
#### **Example Output for XGBoost Model Only:**  
```
[0]     train-logloss:0.66716   val-logloss:0.67121
[50]    train-logloss:0.28482   val-logloss:0.35612
[100]   train-logloss:0.21781   val-logloss:0.32199
[150]   train-logloss:0.18901   val-logloss:0.31459
[200]   train-logloss:0.17055   val-logloss:0.31356
[214]   train-logloss:0.16546   val-logloss:0.31316
Final Model Accuracy: 0.89
```

### **Run XGBoost with LangChain for Text Processing:**  
```bash
python xgboost_langchain.py
```
#### **Example Output for XGBoost + LangChain:**  
```
[0]     train-logloss:0.66716   val-logloss:0.67121
[50]    train-logloss:0.28422   val-logloss:0.35469
[100]   train-logloss:0.21863   val-logloss:0.32441
[150]   train-logloss:0.18764   val-logloss:0.31516
[190]   train-logloss:0.17194   val-logloss:0.31493
Final Model Accuracy: 0.90
```

### **Run XGBoost with Visualization & Saved Plots:**  
```bash
python xgboost_plots.py
```
#### **Generated Plots (Saved in `plots/` Directory):**  
- ğŸ“Š `training_vs_validation_loss.png` â†’ Training vs Validation Loss Curve  
- ğŸ“Š `feature_importance.png` â†’ Feature Importance Plot  
- ğŸ“Š `prediction_distribution.png` â†’ Prediction Probability Distribution  

---

## âš™ï¸ Configuration  
Modify `xgboost_plots.py` to adjust:  
- `learning_rate`
- `max_depth`
- `n_estimators`
- Feature engineering techniques  
- Plot customizations (colors, labels, save paths)  

---

## ğŸ”¥ LangChain Integration  
This project includes **LangChain** to process text data and extract numerical features for XGBoost. The integration uses:  
âœ… **Sentiment Analysis** â€“ Convert feedback into sentiment scores  
âœ… **Topic Extraction** â€“ Categorize text into relevant topics  
âœ… **LLM-based Feature Engineering** â€“ Extract key insights from text  

Example usage in `xgboost_langchain.py`:  
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4", openai_api_key=openai_api_key)
response = llm.invoke("Analyze sentiment of this text: 'Great service!' Return a number from -1 to 1.")
sentiment_score = float(response.content)
```
These scores are then used as input features for XGBoost.  

---

## ğŸ“Š Feature Importance  
To visualize the most important features:  
```python
import xgboost as xgb
import matplotlib.pyplot as plt

xgb.plot_importance(model)
plt.title("Feature Importance")
plt.show()
```

---

## ğŸ›  Future Enhancements  
ğŸ”¹ Optimize hyperparameters using **GridSearchCV**  
ğŸ”¹ Add model **explainability (SHAP values)**  
ğŸ”¹ Expand text processing with **BERT or OpenAI embeddings**  
ğŸ”¹ More customizable plot styles and additional metrics  

---

## ğŸ† Contributing  
Feel free to fork, modify, and submit a pull request! ğŸš€  

---

## ğŸ“œ License  
MIT License Â© 2025 Maki Dizon

